# app_with_encrypted_storage.py
import os
import zipfile
from pathlib import Path
import tempfile
import shutil
from PIL import Image
from pydub import AudioSegment
import torch
import torchaudio
import gradio as gr
from supabase import create_client, Client
import uuid
from cryptography.fernet import Fernet

# =========================
# Ø§ØªØµØ§Ù„ Ø¨Ù‡ Supabase
# =========================
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

TABLE_NAME = "ai_files"
STORAGE_BUCKET = "ai-storage"

# =========================
# Ú©Ù„ÛŒØ¯ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ (Ù†Ú¯Ù‡Ø¯Ø§Ø±ÛŒ Ø¯Ø± Environment Variable)
# =========================
ENCRYPTION_KEY = os.getenv("ENCRYPTION_KEY")
fernet = Fernet(ENCRYPTION_KEY)

# =========================
# Ù…Ø³ÛŒØ±Ù‡Ø§ÛŒ Ù…Ø­Ù„ÛŒ
# =========================
ZIP_PATH = "All_in_One_Final.zip"
EXTRACT_PATH = "Extracted_Files"
os.makedirs(EXTRACT_PATH, exist_ok=True)

# =========================
# Ù…Ø¯Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª
# =========================
bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H
asr_model = bundle.get_model()

def audio_to_text(path: Path):
    waveform, sample_rate = torchaudio.load(path)
    with torch.inference_mode():
        emissions, _ = asr_model(waveform)
        tokens = torch.argmax(emissions[0], dim=-1)
        transcript = bundle.decode(tokens)
    return transcript

# =========================
# Ù¾Ø±Ø¯Ø§Ø²Ø´ ØªØµÙˆÛŒØ±
# =========================
def process_image(path: Path):
    ext = path.suffix.lower()
    if ext in ['.heic', '.heif']:
        img = Image.open(path)
        new_path = path.with_suffix('.jpg')
        img.save(new_path, format="JPEG")
        return new_path
    return path

# =========================
# Ø°Ø®ÛŒØ±Ù‡ ÙØ§ÛŒÙ„ ØªÙˆ Supabase Ùˆ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ
# =========================
def upload_file_encrypted(file_path: Path, file_type: str, transcript=None):
    file_id = str(uuid.uuid4())
    storage_path = f"{file_id}_{file_path.name}"

    # Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„ Ùˆ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ
    with open(file_path, "rb") as f:
        encrypted_data = fernet.encrypt(f.read())
    
    # Ø¢Ù¾Ù„ÙˆØ¯ Ø¨Ù‡ Storage
    supabase.storage.from_(STORAGE_BUCKET).upload(storage_path, encrypted_data, {"upsert": True})
    
    file_url = f"{SUPABASE_URL}/storage/v1/object/public/{STORAGE_BUCKET}/{storage_path}"
    
    # Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ù…ØªÙ†
    encrypted_transcript = fernet.encrypt(transcript.encode()).decode() if transcript else None
    
    # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ø¬Ø¯ÙˆÙ„
    supabase.table(TABLE_NAME).insert({
        "id": file_id,
        "file_name": file_path.name,
        "file_type": file_type,
        "file_path": file_url,
        "transcript": encrypted_transcript
    }).execute()
    
    return file_url

# =========================
# Ù¾Ø±Ø¯Ø§Ø²Ø´ ZIP
# =========================
def process_zip(zip_path):
    shutil.rmtree(EXTRACT_PATH, ignore_errors=True)
    os.makedirs(EXTRACT_PATH, exist_ok=True)

    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(EXTRACT_PATH)
    
    uploaded_files = []
    
    for f in Path(EXTRACT_PATH).rglob("*"):
        if f.is_file():
            if f.suffix.lower() in ['.wav', '.mp3', '.m4a']:
                text = audio_to_text(f)
                url = upload_file_encrypted(f, "audio", transcript=text)
                uploaded_files.append(f"{f.name} -> {url}")
            elif f.suffix.lower() in ['.jpg', '.png', '.heic', '.heif']:
                new_img = process_image(f)
                url = upload_file_encrypted(new_img, "image")
                uploaded_files.append(f"{new_img.name} -> {url}")
            elif f.suffix.lower() == '.txt':
                url = upload_file_encrypted(f, "text")
                uploaded_files.append(f"{f.name} -> {url}")
    
    return "âœ… ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ Ø´Ø¯Ù†Ø¯:\n" + "\n".join(uploaded_files)

# =========================
# Ú†Øª Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡
# =========================
def chat(user_input):
    temp_txt = Path(tempfile.gettempdir()) / f"{uuid.uuid4()}.txt"
    temp_txt.write_text(user_input, encoding="utf-8")
    upload_file_encrypted(temp_txt, "text", transcript=user_input)

    resp = supabase.table(TABLE_NAME).select("*").order("created_at").execute()
    history = ""
    if resp.data:
        for row in resp.data:
            transcript = fernet.decrypt(row["transcript"].encode()).decode() if row.get("transcript") else ""
            if row["file_type"]=="text":
                history += f"ğŸ‘¤ {row['file_name']} -> {transcript}\n"
            else:
                history += f"ğŸ“ {row['file_type'].upper()} {row['file_name']}\n"
    else:
        history = "Ù‡Ù†ÙˆØ² Ú†ÛŒØ²ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ù†Ø´Ø¯Ù‡."
    return "Ù¾ÛŒØ§Ù… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ âœ…", history

# =========================
# Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Gradio
# =========================
with gr.Blocks() as demo:
    gr.Markdown("## ğŸ¤– AI_All_in_One Ø¨Ø§ Ø­Ø§ÙØ¸Ù‡ Ùˆ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§ÛŒ Ø±Ù…Ø²Ù†Ú¯Ø§Ø±ÛŒâ€ŒØ´Ø¯Ù‡")

    with gr.Row():
        zip_input = gr.Textbox(label="Ù…Ø³ÛŒØ± ZIP (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)", placeholder=ZIP_PATH)
        process_btn = gr.Button("Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ø¢Ù¾Ù„ÙˆØ¯ ZIP")

    zip_output = gr.Textbox(label="Ø®Ø±ÙˆØ¬ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„â€ŒÙ‡Ø§")

    with gr.Row():
        user_input = gr.Textbox(label="Ù¾ÛŒØ§Ù…ØªÙˆ Ø¨Ù†ÙˆÛŒØ³:")
        send_btn = gr.Button("Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…")

    ai_output = gr.Textbox(label="Ù¾Ø§Ø³Ø® AI")
    history_output = gr.Textbox(label="ØªØ§Ø±ÛŒØ®Ú†Ù‡ Ú©Ø§Ù…Ù„", lines=15)

    process_btn.click(process_zip, inputs=[zip_input], outputs=[zip_output])
    send_btn.click(chat, inputs=[user_input], outputs=[ai_output, history_output])

demo.launch(share=True)
